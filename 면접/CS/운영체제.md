# 운영체제?
시스템의 자원과 동작을 효율적으로 관리하는 소프트웨어

user interface 제공, 자원 관리, 프로세스와 스레드 관리의 역할을 합니다.

System call Interface, Kernel, Resource Management로 구성되어있습니다.

* System call 
    * 운영체제에서 사용자가 사용할 수 있는 기능들을 모아놓은 인터페이스
* Kernel
    * 자원관리, 하드웨어 관리 등 실질적인 OS 기능들

## 운영체제 구조
* 커널(Kernel)
    * 메모리에 상주하며 processor, memory등 시스템을 관리하여 줍니다
    * OS의 핵심 부분
        * 메모리에 상주한다
        * 가장 빈번하게 사용되는 기능들 담당
        * 시스템 관리(processor, memory 등)
* 유틸리티
    * 비상주 프로그램
    * UI 등 서비스 프로그램

하드웨어로부터 입력받는 커널, 커널의 인터페이스인 system calls, 그 위에 유틸리티

### 계층 구조
OS는 계층구조를 띈다?

## 운영체제 기능
* 프로세스 관리
    * 커널에 등록된 실행 단위
        * 실행 중인 프로그램을 의미
    * 사용자 요청/프로그램의 수행 주체(entity)
* OS의 프로세스 관리 기능
    * 생성/삭제, 상태관리
    * 자원할당
    * 프로세스 간 통신 및 동기화
    * 교착상태(deadlock) 해결
        * 여러 프로세스가 하나의 자원에 동시에 접근하는 것
* 프로세스 정보 관리
    * PCB

* 프로세서 관리
* 프로세서란? 중앙처리장치(CPU)
    * 프로그램을 실행하는 핵심 자원
* 프로세스 스케줄링(Scheduling)
    * 시스템 내의 프로세스 처리 순서 결정
* 프로세서 할당 관리
    * 프로세스들에 대한 프로세서 할당
    * 한 번에 하나의 프로세스만 사용 가능


* 메모리 관리
* 주기억장치를 의미
    * 작업을 위한 프로그램 및 데이터를 올려 놓는 공간
* Multi-tasking
    * 프로세스에 대한 메모리 할당 및 회수
    * 메모리 여유 공간 관리
* 메모리 할당 방법
    * 일부 적재(virtual memory concept)
        * 프로그램 및 데이터의 일부만 적재
        * 메모리 효율적 활용

## 프로세스
실행을 위해 커널에 등록되어 메모리를 할당 받은 프로그램

처리가 필요한 프로그램과 필요한 데이터를 하나의 Job(프로그램)이라고 한다.

이것을 시스템에 처리해달라고 요청하는데 그렇게 등록된 Job을 Process라 한다.
* 보조 메모리에 있던 프로그램이 실행을 위해 메모리로 올라간 것


* PCB(Process Control Block)
    * OS가 프로세스 관리에 필요한 정보 저장공간
    * 프로세스 생성 시, 커널에 PCB가 생성 됨

### 프로세스 상태
* Create
    * 프로그램이 커널에 등록되어 메모리를 할당받은 상태
* Active
    * Ready : 기타자원
    * Running : 기타자원, 프로세서
        * Ready에서 running으로 바뀌는 것을 **dispatch**라 한다.
    * Blocked, asleep : 암것도없음
        * Running에서 Blocked로 가는 것을 **인터럽트**라고 함
* Suspended
    * 메모리가 없음
* terminated
    * 수행이 끝난 상태
    * 모든 자원이 반납되고 일부 PCB 정보만 남은 상태

### Context Switching(문맥 교환)
* Context
    * 프로세스와 관련된 정보들의 집합
        * CPU 레지스터 혹은 PCB, stack 등 메모리에 있다
* Context switching 
    * 실행중인 프로세스의 context를 저장하고, 앞으로 실행 할 프로세스의 context를 복구하는 일
    * context를 PCB에 저장한다
    * 커널이 한다

context switching은 비용이 소모되는 작업이고 자주 일어나게 된다.

가능하면 줄이는 것이 좋다. 대표적으로 스레드를 사용하여 줄일 수 있다.

## 자원(Resource)
커널의 관리 하에 프로세스에게 할당/반납 되는 수동적 개체

H/W 자원과, S/W 자원이 있다

## 프로세스와 스레드
* 스레드
    * 프로세스가 할당 받은 자원을 이용하는 실행 단위
    * 여러 개 있을 수 있다
        * 최소 한개 이상(메인 스레드)

* 스레드 장점
    * 자원 공유 가능하여 효율성 증가(커널의 개입을 피할 수 있다)
    * 커널의 개입이 필요한 컨텍스트 스위치를 피할 수 있다
    * 멀티 프로세서를 활용하여 병렬처리를 통하여 성능을 향상시킬 수 있습니다.


## 다중 프로그래밍
* 여러개의 프로세스가 시스템 내 존재 -> 자원을 나눠 사용해야 함
* 자원을 할당 할 프로세스를 선택해야 함
    * 스케줄링
* 자원관리 방법
    * 시간 분할 관리
        * 하나의 자원을 여러 스레드들이 번갈아 가며 사용
        * 프로세서 등
        * 프로세스 스케줄링(process scheduling) 
            * 프로세서 사용시간을 프로세스들에게 분배
    * 공간 분할 관리
        * 하나의 자원을 분할하여 동시에 사용
        * 메모리 등

## 스케줄링
프로세스들에게 자원(프로세서)을 할당하는 정책

시스템의 성능 향상을 위해 사용한다.

성능이란 응답시간, 처리량, 자원 활용도를 의미한다.

## 스케줄링 정책
선점 vs 비선점
* 비선점
    * 할당 받을 자원을 스스로 반납할 때까지 사용
    * 평균 응답시간이 크다
* 선점 
    * 타의에 의해 자원을 빼앗길 수 있음
    * Context switch overhead가 큼

최근의 OS는 모두 선점형 OS이다.

윈도우에서는 우선순위 스케줄링과 RR을 합친 스케줄링을 사용한다
* 우선순위 높은 프로세스에 할당 + RR

## 비선점
* FCFS
    * 레디 큐에 먼저 도착한 프로세스에 먼저 처리
    * 일괄처리 시스템에 적합, 대화형 시스템에는 부적합
    * 장점
        * 스케줄링에 대한 부담이 없다
    * 단점
        * 중요한 프로세스가 기다려야할 수 있다
* SJF(Shortest-Job-First)
    * 가장 실행시간이 작은 프로세스를 먼저 처리
    * 장점
        * 평균 대기시간을 최소화 시킬 수 있다
    * 단점
        * Starvation(무한대기) 현상 발생 가능
        * 실행시간을 예측해야 한다

## 선점
* RR(Round-Robin)
    * 먼저 도착한 순으로 처리하지만 제한 시간이 있다
    * 할당된 시간이 지나면 자원을 반납한다
    * 대화형, 시분할 시스템에 적합하다
* SRTN(Shortest Remaining Time Next)
    * 실행시간이 가장 적게 남은 프로세스가 ready 상태가 되면 선점
    * 장점
        * SPN 장점 극대화
        * 평균대기시간을 최소화 가능
    * 단점
        * 총 실행시간 예측이 필요하다
* HRRN(High-Response-Ratio-Next)
    * SPN의 변형
    * 실행시간 + 대기시간, aging이라고도 한다

### MLQ
작업 우선순위별 여러 개의 큐를 가진다

Queue 사이에는 우선순위 기반의 스케줄링을 사용한다

Queue는 각자의 스케줄링을 가짐

우선순위가 낮은 queue는 starvation현상이 있을 수 있다

queue 사이에 프로세스가 이동 가능한 MFQ(Multi Level Feedback Queue)도 있다


## Process 동기화
* 다중 프로그램 시스템
    * 여러 프로세스가 존재
    * 프로세스는 서로 독립적
    * 공유 자원이 있다면 문제 발생 가능
* 동기화(Synchronization) 필요

* Shared data(공유 데이터)
* Critical section(임계 영역)
    * 공유 데이터를 접근하는 코드 영역
* Mutual exclusion(상호배제)
    * 둘 이상의 프로세스가 동시에 critical section에 접근하는 것을 막는 것

## 블록 논블록 동기 비동기
블록/논블록은 함수호출에서의 이야기

* 블록 
    * 함수를 호출하였을 때 기대하는 행위를 모두 끝마칠 때까지 기다렸다 리턴되는 것
* 논블록
    * 기대하는 어떤 행위를 요청하고 바로 리턴

* 동기
    * 두 행위가 순차적으로 작동하면 동기
* 비동기
    * 동시에 실행된다면 비동기

* 블록/동기
    * A가 B요청후 끝나기를 기다리다 끝난거 받고 자기할일아는것
* 블록/비동기
    * A가 B요청 후 자기할일하다가 B가 처리되는지 기다리다가 됬으면 처리
* 논블록/동기
    * B요청 후 A는 B가 완료됬는지 수시로 확인, 완료됬으면 자기할일함
* 논블록/비동기
    * B요청 후 할일하다 버퍼 찼으면 작업

### 동기화 방법 SW
* Dekker's Algorighm, Peterson's Algorithm
    * flag와 turn이라는 변수로 임계영역에 들어갈 프로세스(혹은 스레드) 결정
    * flag는 프로세스 중 임계 구역에 들어가길 원하는지 나타낸다
    * turn은 누가 임계영역에 들어갈 차례인지 나타낸다
* Dijkstra's Algorithm
    * n개의 프로세스
    * 똑같이 flag 1~n까지의 turn
    * 반복문을 돌며 turn 검사
* SW적인 방법들이다
    * 속도가 느리고
    * 기다리며 게속 도는 문제가 있다
        * busy wait

### 동기화 방법 OS
* Spinlock
    * 정수 변수
    * 초기화 연산으로만 접근 가능
        * atomic하고 OS가 보장해준다
    * 들어가면 +, 나오면 -하도록 구현
    * busy waiting
* Semaphore
    * 음이 아닌 정수형 변수 S
        * 초기화 연산으로만 접근 가능
        * P(): 검사, V(): 증가
        * atomic 하도록 OS가 보장
    * 만약 자원을 누군가가 사용하고 있다면 readyQueue에서 대기한다
    * 프로세스가 자원 사용이 끝나면 readyQueue를 호출합니다
        * 참고로 비결정적
    * busy waiting 문제 해결

## 교착상태(Deadlock)
두 개 이상의 프로세스나 스레드가 서로 자원을 기다리며 무한히 기다리는 상태

서로 상대방의 작업이 끝나기를 기다리기 때문에 다음 상태로 진행하지 못하고 있는 상태이빈다.

starvation은 운이나 운선순위에서 밀리는 것이라면 deadlock은 일어날 가능성이 없는 상태

### Deadlock의 4가지 조건
1. 상호배제
    * 동시 접근 불가
2. 점유와 대기(hold and wait)
    * 하나의 자원을 소유하고 다른 프로세스 혹은 스레드의 자원을 요청
3. 비선점(non-preemptive)
    * 스스로 놀기 전에는 뺏을 수 없다
4. 환형 대기(circlar wait)
    * 각 프로세스가 다음 프로세스가 요구하는 자원을 가지고 있는 것

### 교착상태 해결 방법
4가지 조건 중 하나라도 제거하면 된다.

해결 방법으로는 예방, 회피, 탐지 및 복구가 있다.

1. 예방 
    * 교착상태가 발생하지 않도록 하는 것
2. 회피
    * 교착상태를 피하는 것
    * Banker's Algorithm
3. 탐지
    * 교착상태가 발생하면 탐지 하는 것, 복구를 수반
    * unblocked(자원 다 가짐) 된 process에 edge를 지워갔을 때 edge남으면 교착
4. 복구
    * 프로세스를 중지, 자원 선점

### Deadlock Avoidance
* Banker's Algorighm
    * 회피
    * 프로세스에 자원을 할당한 후에도 안전 상태로 남아있는지 사전에 검사하는 기법
    * 안전 상태면 자원 할당, 그렇지 않으면 다른 프로세스들이 자원을 해지할 때까지 대기
    * 항상 시스템을 감시해야 하고
    * safe 유지를 위해, 사용 되지 않는 자원이 존재

* safe state
    * 모든 프로세스가 정상적 종료 가능한 상태
    * Deadlock상태가 되지 않음을 보장
* unsafe state
    * Deadlock 상태가 될 가능성이 있음

## 메모리의 종류
레지스터, 캐시, 메인 메모리, 보조기억장치 

앞일수록 빠르고 작고 비싸다

* Block : 메인과 보조 메모리 사이의 전송 단위
* Word : 주기억장치와 레지스터 사이의 데이터 전송 단위

### Address Binding
프로그램의 논리 주소를 실제 메모리의 물리 주소로 매핑하는 작업

보통 런타임에 Binding함

## 메모리 할당
Fixed Partition Multiprogramming
* 메모리를 고정된 크기로 미리 분할
* 각 프로세스는 하나의 partition에 적재
    * Continous Memory allocation
* Partition의 수 = K
* 메모리 관리가 간편함
* 시스템 자원 낭비될 수 있음
    * 내부, 외부 단편화

Variable Partiotion Multiprogramming
* 동적으로 분할
* 내부단편화는 발생하지 않는다
* 외부단편화는 발생

OS에서는 메모리를 할당하는 방법에는 가변분할방식과 고정분할 방식이 있습니다.
고정분할방식은 ~~ 가변분할방식은 ~ 가 있습니다

### 단편화
내부 단편화
* Partition 크기 > Process 크기 인 경우
* 메모리가 낭비됨

외부 단편화
* 남은 메모리 크기 > Process 크기
* 하지만 연속된 공간이 아니라 할당할 수 없다
* 메모리 낭비됨

### 가변 분할 방식 배치 전략
* First-fit(최초 적합)
    * 충분한 크기를 가진 첫 번째 partition 선택
* Best-fit(최적 적합)
    * 들어갈 수 있는 것 중 가장 작은 크기를 가진 partition 선택
    * 작은 크기의 partition이 많이 생긴다
    * 크기가 큰 partition을 유지할 수 있다
* worst-fit(최악 적합)
    * process가 들어갈 수 있는 partition 중 가장 큰 곳 선택
    * 작은 partition이 준다
    * 큰 partition도 준다
* Next-fit(순차 최초 적합)
    * 최초 적합 전략과 유사
    * State table에서 마지막으로 탐색한 위치부터 탐색
    * 메모리 영역 사용 빈도 균등화

### 가변 분할 방식 외부 단편화 해결
* 공간 통합
    * 인접한 빈 영역을 하나의 partitoion으로 통합
    * Process가 memory를 release하고 나가면 수행한다
* 메모리 압축
    * 떨어진 메모리 영역을 모아 하나로 통합
    * 프로세스 처리에 필요한 적재 공간 확보가 필요할 때 수행
    * 모든 프로세스를 재배치해야 하기 때문에 부하가 매우 크다

## 가상 기억 장치
보조기억장치의 일부를 마치 메모리처럼 사용하는 것.

continous allocation과는 달리 프로그램을 block 단위로 분할하여 저장하게 되는데 실행 시, 필요한 block만 메모리에 적재하고 나머지는 보조메모리의 swap device에 적재하게 됩니다.

프로그램은 가상 메모리에 할당되고, 해당 가상 메모리를 통하여 실제 주소에 접근함

이때 가상 메모리주소를 가상 주소, 실제 메모리 주소를 물리 주소

CPU는 가상 주소를 통하여 마치 모든 프로그램이 메모리에 적재되어 있는 것처럼 처리 가능, 필요시 mapping을 통해 실제 주소에 접근합니다.

만약 가상 주소를 통하여 접근하고자 했으나 실제 메모리에 적재되어있지 않은 경우를 Page fault라 합니다.

page fault의 경우 context switch가 일어나게 됩니다. 프로세스는 프로세서를 반납하고 asleep 상태가 됩니다.

이 경우 swap device에서 메모리로 필요한 block을 가져와야 합니다.

## page fault를 줄이기 위한 할당 전략
* write back : 메모리의 변경사항을 swap device에 반영
https://github.com/JaeYeopHan/Interview_Question_for_Beginner/tree/master/OS

## 가상메모리
메모리 관리 기법, 프로세스 전체가 메모리 내에 올라오지 않더라도 실행이 가능하도록 하는 기법

프로세스를 필요한 부분만 메모리에 올려놓고 실행한다.

CPU입장에서는 런타임 바인딩을 통해 마치 전부 올라와있는 것처럼 사용할 수 있다.

프로세스를 메모리에 올리는 것을 페이징 기법이라 한다. 프로세스를 블록 크기로 나누게 되고, 메모리도 블록 크기로 나누게 된다. 여기서 메모리나눈것을 페이지라 한다.

여기서 지금 필요한 페이지만 메모리에 올려놓고 사용하게 된다.

메핑 테이블에 해당 페이지가 올라왔는지를 표시

만약 CPU가 메모리에서 찾는데 없다면 페이지 폴트

os가 swap영역에서 해당 page를 가져오게 된다.

필요한 프로세스가 메인메모리에 없다면 스왑영역에 있는 메모리를 가져와야 함

장점
* 사용자 프로그램이 물리 메모리 제약에서 벗어남
* 각 프로그램이 더 작은 메모리를 차지하기 때문에 더 많은 프로그램을 동시수행 가능
* 프로그램을 메모리에 올리고 swap 하는데 필요한 IO 횟수가 줄어듦

## 프로그램이 실행되는 것이란?
CPU는 메인메모리까지의 값만 참조할 수 있다

메인메모리에 없는 블록은 운영체제가 IO해줘야 함

논리주소
* CPU는 실행파일 실행 시 프로세스마다 독자적인 주소공간을 생성함
* 그리고 해당 주소를 바라보게 된다. 이것을 논리주소라고 한다
* CPU가 일을 하기 위해서는 논리 주소가 메인메모리상에 올라와있어야 함
* 논리주소는 물리적 메모리의 특정위치로 매핑됨, 이것을 주소바인딩
* 실행 시간 바인딩을 이용하여 논리주소를 물리주소로 바인딩시켜줘야 함
* CPU가 주소를 참조할때마다 주소 매핑 테이블을 이용해 바인딩

스왑영역
* 디스크에 존재하여 메인메모리에 있는 프로세스가 다 안올라갈 경우 swap 영역에 있는다
* swap영역에서 메모리로 데이터가 인아웃하는 것을 swap in, swap out이라 한다



## Virtual Storage(memory)
* Non-continous allocation
    * 외부 단편화 해결 가능
    * 사용자 프로그램을 여러 개의 block으로 분할
    * 실행 시, 필요한 block들만 메모리에 적재
        * 나머지 block들은 swap device(보조메모리)에 존재
    * 가상주소에 할당하고, 이것이 실제 주소와 매핑됨
    * Address mapping
        * virtual address를 물리 주소로 바꿔주는 것
        * BMT로 접근한다.

* Memory Management
    * Page frame와 같은 크기로 미리 나눈다


## paging system
프로그램을 같은 크기의 블록으로 분할한다고 했는데 이것을 Page라 한다.

메모리도 block size로 미리 분할하게 된다.

외부 단편화 문제는 없다.

필요한 page만 page frame에 적재하여 사용한다.
* 현재 필요없는 것은 보조기억장치에 저장

* Page
    * 프로그램의 분할된 block
* Page frame
    * 메모리의 분할 영역
    * Page와 같은 크기로 분할하면 된다
* 프로그램을 Page크기로 자른다
    * 논리적 분할이 아닌 크기에 따른 분할
    * 간단함
    * 내부 단편화 발생, 외부 단편화는 발생 안함

### Page Sharing
여러 프로세스가 특정 page공유 가능
* Non-continous allocation

## Segmentation System
* 물리적이 아닌 논리적으로 분할
    * Block 크기가 서로 다를 수 있다
    * stack, heap 등
    * 미리 메모리를 분할 불가
        * 동적으로 분할해야 한다
    * 외부 단편화 발생, 내부 단편화 발생안함
* 장점
    * 논리적으로 분할되어 공유 및 보호가 용이함
* 단점
    * paging system 대비 overhead가 큼

## Virtual Memory Management
* 가상 메모리
    * Non-continous allocation
        * 사용자 프로그램을 block 단위로 분할하여 적재
    * Paging/Segmentation system

* 가상 메모리 관리 목적
    * 시스템 성능 최적화

* Page fault
    * 메모리는 일정한 page frame 단위로 잘려있다
    * 프로세스는 swap device에 존재하는데
    * 이 중 사용하는 것을 메모리에 page frame 단위로 올린다
    * CPU는 메모리를 참조하여 데이터를 처리한다
    * CPU가 참조하고자 하는 데이터가 메모리에 없는 경우 page fault
    * page fault가 발생하면 프로세서가 처리하는 프로세스를 뺏기는 context switch 일어남


## 지역성
빠른 장치에서 느린장치간 성능차이로 병목현상 발생

캐시메모리는 이런 병목현상을 줄이기 위한 범용 메모리

지역성의 원리를 이용한다, 어느 한 부분에 집중적으로 참조한다는 특성으로 시간 지역성과 공간지역성이 있습니다, 참조한것은 다시 참조, 인접한 내용 참조

지역성 활용 사례

LRU 같은 캐시 교체 알고리즘

FIFO, LFU 등 다른 캐시 교체 알고리즘도 있다


## 페이지 교체 알고리즘
* FIFO
    * 가장 먼저 들어온 페이지 내린다
* OPT
    * 
* LRU(Least Recently Used)
    * 가장 오래전 사용한 페이지를 교체
    * 시간적 지역성, OPT과 비슷하다
* LFU(Least Frequently Used)
    * 가장 적게 사용된 페이지를 내린다



## 프로그램 실행 과정
![](https://i.imgur.com/fbzJjII.png)

사용자가 프로그램 실행요청을 하면 OS가 그것을 받아 보조기억장치에서 필요한 정보를 읽어 메모리에 로드합니다.

CPU는 프로그램 코드를 가져다 메모리를 관리하고 명령문을 실행합니다.





















# 출처
https://jinshine.github.io/2018/05/17/%EC%BB%B4%ED%93%A8%ED%84%B0%20%EA%B8%B0%EC%B4%88/%EB%A9%94%EB%AA%A8%EB%A6%AC%EA%B5%AC%EC%A1%B0/
